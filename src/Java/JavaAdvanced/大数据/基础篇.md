---
icon: bugs
date: 2022-01-09
category:
  - hadoop
tag:
  - hadoop
  - 集群
  - 云主机
---

# hadoop集群搭建

## 添加ip映射

````shell
vim /etc/hosts
````

添加

````

172.31.0.205    master
172.31.0.172    salve1
172.31.0.134    salve2
````

## 实现主机之间的免ssh密登录

```shell
#安装ssh的server端
apt-get install openssh-server
#测试
ssh localhost
#生成密钥对  id_rsa.pub, id_rsa
ssh-keygen -t rsa
#将A的公钥发给B，并添加到authorized_keys末尾.B可以免密登录A
cat ~/.ssh/id_rsa.pub | ssh -p 22 主机B的名称@主机B的ip 'cat >> ~/.ssh/authorized_keys'
```

* 注意：要配置master的自己的ssh免密登录，把自己的id_rsa.pub添加到authorized_keys的末尾

* ```shell
  cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys
  ```

![](/assets/images/屏幕截图 2021-09-13 112050.png)

> 配置多余的id_rsa.pub,会导致在进行ssh连接的时候，出现查找密钥的冲突。
>
> 解决方法：删除在authorized_keys中冲突的公钥.

## 装java



apt-get install openjdk-8-jdk

````shell
java安装路径:/usr/lib/jvm/java-8-openjdk-amd64
````

## 装hadoop

````shell
cd /opt/software
wget https://repo.huaweicloud.com/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
tar -zxvf hadoop-2.7.7.tar.gz -C /opt/apps/
````

### 配置java和hadoop环境变量

```shell
cd /opt
sudo mkdir env
cd env/
sudo vim bigdata.sh
```

在bigdata.sh中添加

```shell
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$PATH:$JAVA_HOME/bin
export HADOOP_HOME=/opt/apps/hadoop-2.7.7
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

```shell
cd ~
vim .bashrc
```

在.bashrc末尾添加

```shell
source /opt/env/bigdata.sh
```

### Hadoop配置文件修改

##### 修改core-site.cml

````shell
vim /opt/apps/hadoop-2.7.7/etc/hadoop/core-site.xml
````

```xml
<configuration>
<property>
 <!-- 默认文件系统的名称,一个URI和权威确定文件系统实现的方案。uri的权威是用来确定主机、端口等对于一个文件系统-->
 <name>fs.defaultFS</name>
 <value>hdfs://master:8020</value>
 </property>
</configuration>
```

##### 修改hdfs-site.xml

````shell
vim /opt/apps/hadoop-2.7.7/etc/hadoop/hdfs-site.xml
````

````xml
<configuration>
<!-- 设置副本数量为3-->
<property>
 <name>dfs.replication</name>
 <value>3</value>
</property>
<!-- 保存FsImage镜像的目录,作用是存放hadoop的名称节点namenode里的metadata元数据；-->
<property>
 <name>dfs.namenode.name.dir</name>
 <value>/bigdata/data/hdfs-name</value>
</property>
<!-- 存放HDFS文件系统数据文件的目录，作用是存放hadoop的数据节点datanode里的多个数据块。-->
<property>
 <name>dfs.datanode.data.dir</name>
 <value>/bigdata/data/hdfs-data</value>
</property>
    <!-- 配置第二名称节点的http服务器地址以及端口 -->
<property>
 <name>dfs.namenode.secondary.http-address</name>
 <value>salve2:50090</value>
</property>
</configuration>
````

##### 修改mapred-site.xml

````shell
vim /opt/apps/hadoop-2.7.7/etc/hadoop/mapred-site.xml
````

```xml
<configuration>
    <!-- 指明hadoop的MR将来运行于YARN上。Yarn为资源调度系统（可运行MR,STORM,SPARK等计算框架）-->
<property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
</property>
    <!--将历史服务器配置在master中，默认端口10020 -->
<property>
 <name>mapreduce.jobhistory.address</name>
 <value>master:10020</value>
</property>
    <!-- 实现web查看作业的历史运行情况 -->
<property>
 <name>mapreduce.jobhistory.webapp.address</name>
 <value>master:19888</value>
</property>
</configuration>
```

##### 修改yarn-site.xml

```shell
vim /opt/apps/hadoop-2.7.7/etc/hadoop/hdfs-site.xml
```

```xml
<configuration>
   <!-- 资源管理器的主机名称 -->
<property>
 <name>yarn.resourcemanager.hostname</name>
 <value>salve1</value>
</property>
    <!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序 -->
<property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
</property>
</configuration>
```

##### 修改salves文件(在hadoop3.x中为workers)

```shell
vim /opt/apps/hadoop-2.7.7/etc/hadoop/salves
```

```txt
master
salve1
salve2
```

##### 分发修改过后的hadoop配置文件

````shell
rsync -av /opt/apps/hadoop-2.7.7/etc/hadoop/ root@salve1:/opt/apps/hadoop-2.7.7/etc/hadoop/
````

###### 注意

在master节点上，配置了NameNode, NodeManager, DataNode,  JobHistoryServer

在salve1节点上，配置了ResourceManager，NodeManager, 

DataNode

在salve2节点上，配置了SecondaryNameNode，NodeManager，DataNode

+ 如果在完全分布式部署，Namenode和ResourceManger如果不是同一台机器，不能在NodeManager上启动 yarn，应该在ResourceManager所在的机器上启动yarn

#### 初始化HDFS

```shell
hdfs namenode -format
```

#### 启动hadoop

```shell
#注：不可以直接在master节点上运行 start-all.sh
#应该分别开启
root@master:/opt#start-dfs.sh
root@salve1:/opt#start-yarn.sh
root@master:/opt#mapred --daemon start historyserver
```

##### 编写Hadoop启动脚本

```shell
#!/bin/bash

if [ $# -lt 1 ]
then
	echo "NoArgs Input"
	exit;
fi

case $1 in
"start")
	echo "=============== starting Hadoop Cluster ==============="
	echo "--------------- starting HDFS ---------------"
	ssh master "/opt/apps/hadoop-2.7.7/sbin/start-dfs.sh"
	echo "--------------- starting Yarn ---------------"
	ssh salve1 "/opt/apps/hadoop-2.7.7/sbin/start-yarn.sh"
	echo "--------------- starting JobHistoryServer----------------"
	ssh master "/opt/apps/hadoop-2.7.7/sbin/mr-jobhistory-daemon.sh start historyserver"
;;
"stop")
	echo "============== stoping Hadoop Cluster =================="
	echo "-------------- stoping JobHistoryServer ----------------"
	ssh master "/opt/apps/hadoop-2.7.7/sbin/mr-jobhistory-daemon.sh stop historyserver"
	echo "-------------- stoping Yarn ------------------"
	ssh salve1 "/opt/apps/hadoop-2.7.7/sbin/stop-yarn.sh"
	echo "-------------- stoping Hadoop Cluster ----------------"
	ssh master "/opt/apps/hadoop-2.7.7/sbin/stop-dfs.sh"
;;
*)
	echo "Input Args Error..."
;;
esac
```

## 装hbase

```shell
cd /opt/software
wget https://repo.huaweicloud.com/apache/hbase/1.4.9/hbase-1.4.9-bin.tar.gz
tar -xzvf hbase-1.4.9-bin.tar.gz -C ../apps/
```

### 配置hbase环境变量

```shell
cd /opt/env
vim bigdata.sh
```

在末尾增加

```shell
export HBASE_HOME=/opt/apps/hbase-1.4.9
export PATH=$PATH:$HBASE_HOME/bin
```

### 修改配置文件

hbase-site.cml、regionservers

#### 修改hbase-site.xml

```shell
vim /opt/apps/hbase-1.4.9/conf/hbase-site.xml
```

```xml
<configuration>
    <!-- HBase集群中所有RegionServer共享目录，用来持久化HBase的数据 -->
<property>
 <name>hbase.rootdir</name>
 <value>hdfs://master:9000/hbase</value>
</property>
    <!-- 集群的模式，分布式还是单机模式，如果设置成false的话，HBase进程和Zookeeper进程在同一个JVM进程。线上配置为true. -->
<property>
 <name>hbase.cluster.distributed</name>
 <value>true</value>
</property>
    <!-- zookeeper集群的URL配置，多个host中间用逗号（,）分割 -->
<property>
<name>hbase.zookeeper.quorum</name> 
<value>master, salve1, salve2</value> 
</property> 
    <!-- 配置zookeeper的默认端口 -->
<property>           <name>hbase.zookeeper.property.clientPort</name>
<value>2181</value>
</property>
</configuration>
```

+ [hbase相应配置参数的解释](https://www.cnblogs.com/nexiyi/p/hbase_config_94.html)

#### 修改regionservers文件

```shell
vim /opt/apps/hbase-1.4.9/conf/regionservers
```

```txt
master
salve1
salve2
```

#### 修改hbase-env.sh

```shell
vim /opt/apps/hbase-1.4.9/conf/hbase-env.sh
```

```shell
#修改第128行
export HBASE_MANAGES_ZK=true
```

#### 分发配置

```shell
rsync -av /opt/apps/hbase-1.4.9/conf/ root@salve1:/opt/apps/hbase-1.4.9/conf/
```

##### 注意

* 使用hbase自带的zookeeper，莫名的2181端口被占用，使用hbase shell 报错。

* 解决方法：在hbase-site.xml中修改默认端口为2080，hbase.zookeeper.property.clientPort

* ```shell
  #查看端口是否被占用
  netstat -anp |grep 端口号
  ```

## 安装mysql

```shell
#下载mysql-server
apt update
apt install mysql-server
#修改mysql的远程连接权限
mysql -u root -p Shuai.4188
use mysql
updata user set host='%' where user='root'
#重启mysql
service mysql stop
service mysql start
```

## 安装hive

```shell
cd /opt/software
wget https://repo.huaweicloud.com/apache/hive/hive-2.3.4/apache-hive-2.3.4-bin.tar.gz
tar -zxvf apache-hive-2.3.4-bin.tar.gz -C ../apps/
```

### 配置hive环境

```shell
cd /opt/env
vim bigdata.sh
```

添加

```shell
export HIVE_HOME=/opt/apps/apache-hive-2.3.4-bin
export PATH=$PATH:$HIVE_HOME/bin
```

### 修改配置文件

#### 修改hive-default.xml.template文件名称

```shell
cp /opt/apps/apache-hive-2.3.4-bin/conf/hive-default.xml.template /opt/apps/apache-hive-2.3.4-bin/conf/hive-default.xml
```

#### 修改hive-site.xml

```shell
vim /opt/apps/apache-hive-2.3.4-bin/conf/hive-site.xml
```

```xml
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 设置元数据连接字串 -->
<property>
 <name>javax.jdo.option.ConnectionURL</name>
 <value>jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true</value>
 <description>the URL of the MySQL database</description>
</property>
    <!-- 关于在hive中用java来开发与mysql进行交互时，需要用到一个关于mysql的connector，这个可以将java语言描述的对database进行的操作转化为mysql可以理解的语句。 -->
<property>
 <name>javax.jdo.option.ConnectionDriverName</name>
 <value>com.mysql.jdbc.Driver</value>
 <description>Driver class name for a JDBC metastore</description>
</property>
    <!-- 用来设置hive存放元数据的数据库(这里是mysql数据库)的用户名称的。 -->
<property>
 <name>javax.jdo.option.ConnectionUserName</name>
 <value>hadoop</value>
</property>
    <!-- 用来设置，用户登录数据库（上面的数据库）的时候需要输入的密码的. -->
<property>
 <name>javax.jdo.option.ConnectionPassword</name>
 <value>hadoop</value>
</property>
    <!-- 设定数据目录 -->
<property>
<name>hive.metastore.warehouse.dir</name>
<value>/opt/apps/apache-hive-2.3.4-bin/warehouse/</value>
</property>
</configuration>
```

```shell
#初始化hive
schematool -dbType mysql -initSchema
```



## 安装spark

```shell
cd /opt/software
wget https://repo.huaweicloud.com/apache/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
tar -zxvf spark-2.4.5-bin-hadoop2.7.tgz -C ../apps
```

### 配置spark环境

```shell
cd /opt/env
vim bigdata.sh
```

添加

```shell
export SPARK_HOME=/opt/apps/spark-2.4.5-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin
```

### 修改spark-defaults.conf配置文件

```shell
vim /opt/apps/spark-2.4.5-bin-hadoop2.7/conf/spark-defaults.conf
```

添加

```shell
spark.yarn.jars=hdfs://master:9000/spark_jars/*
```

###  上传spark jar文件

```shell
hdfs dfs -mkdir /spark_jars
hdfs dfs -put /bigdata/spark-2.4.0-bin-hadoop2.7/jars/* /spark_jars
```

### 配置yarn-site.xml

```shell
vim /opt/apps/hadoop-2.7.7/etc/hadoop/yarn-site.xml
```

```xml
<!-- 是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true。 -->
<property>
<name>yarn.nodemanager.vmem-check-enabled</name>
<value>false</value>
</property>
<!-- 是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true。 -->
<property>
<name>yarn.nodemanager.pmem-check-enabled</name>
<value>false</value>
</property>
```

#### 测试spark

```shell
#进入spark的shell窗口
spark-shell
#退出sparkshell
:quit
```

```shell
#测试自带的spark例子
cd /opt/apps/spark-2.4.5-bin-hadoop2.7
spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster examples/jars/spark-examples*.jar 10
```



## 安装python3.7

Linux环境：ubuntu16.x

千万别删系统自带的python

```shell
apt install software-properties-common
add-apt-repository ppa:deadsnakes/ppa
apt-get update
apt-get intsall python3.7
#更改优先级
update-alternatives --install /usr/bin/python python /usr/bin/python3.7 3
```



